{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster-based Vote Count Prediction for new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading IncV3 latent features sim. matrix and votes\n",
    "SIM_MX_FILE_PATH = os.path.join('..', '..', 'results', 'matrices', 'incv3_feats_euclid_sim_matrix.csv')\n",
    "VOTES_FILE_PATH = os.path.join('..', '..', 'results', 'votes_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lOADING \n",
    "FEATS_FILE_PATH = os.path.join('..', '..', 'results', 'features', 'incv3_feats.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data (Sim. Matrix between images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'../../results/matrices/incv3_feats_euclid_sim_matrix.csv' does not exist: b'../../results/matrices/incv3_feats_euclid_sim_matrix.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-acc1cdf66f49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msim_mx_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSIM_MX_FILE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msim_mx_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../../results/matrices/incv3_feats_euclid_sim_matrix.csv' does not exist: b'../../results/matrices/incv3_feats_euclid_sim_matrix.csv'"
     ]
    }
   ],
   "source": [
    "sim_mx_df = pd.read_csv(SIM_MX_FILE_PATH, index_col=0)\n",
    "sim_mx_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_df = pd.read_csv(VOTES_FILE_PATH, index_col=0)\n",
    "votes_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a sanity check for vote proportion in our the dataset. In the original XAI-CBR paper, vote proportion was like this:\n",
    "- IG: 45%\n",
    "- XRAI: 30%\n",
    "- LIME: 18%\n",
    "- ANCHOR: 7%\n",
    "\n",
    "Also, IG was the most voted technique, at least by hard voting aggregation, with a majority of 62% images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "votes_df[['ig','lime','xrai','anchor']].sum() / 2867"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a slight imbalance of these proportions with respect to ones presented in the paper. It seems like some votes from XRAI and ANCHOR techniques drifted out to the IG technique. We'll check this out later, this should not be of great importance in the experiments of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sim_mx_df.values # Values from sim. matrix\n",
    "X_names = sim_mx_df.index.values # Names of every image\n",
    "y = votes_df.values[:, :4] # Vote count for each imae\n",
    "best = votes_df.values[:, -1] # Most voted technique for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, X_names.shape, y.shape, best.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instance deletion\n",
    "Stratified Subsampling cannot be performed onto the dataset because only one instance is best explained with ANCHOR. Due to the very small importance of that instance in the dataset, we will continue without that instance (i.e. we will find that instance and remove it from the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At what index is the anchor instance located?\n",
    "anchor_idxs = np.argwhere(best == 'anchor')[0]\n",
    "anchor_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the name of that image and its associated technique?\n",
    "X_names[anchor_idxs], best[anchor_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete that instance from all data partitions (X, y, etc.)\n",
    "X = np.delete(X, anchor_idxs, axis=0)\n",
    "X = np.delete(X, anchor_idxs, axis=1) # Twice in sim. matrix (both rows and columns)\n",
    "X_names = np.delete(X_names, anchor_idxs, axis=0)\n",
    "y = np.delete(y, anchor_idxs, axis=0)\n",
    "best = np.delete(best, anchor_idxs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, X_names.shape, y.shape, best.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting and Fold Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit as SSS\n",
    "from sklearn.model_selection import ShuffleSplit as SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this constant to toogle stratified sampling on/off\n",
    "STRATIFIED = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform split\n",
    "splitter = None\n",
    "if STRATIFIED: splitter = SSS(n_splits=5, test_size=0.2, random_state=42)\n",
    "else: splitter = SS(n_splits=5, test_size=0.2, random_state=42)\n",
    "splits = splitter.split(X, best)\n",
    "splits = list(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterable_params = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim_mx_subset(sim_mx_values, filter_idxs):\n",
    "    return sim_mx_values.take(filter_idxs, axis=0).take(filter_idxs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_dbscan_sim_mx(data, min_samples, eps_values, \n",
    "               min_no_clusters=5, max_no_clusters=np.inf,\n",
    "               min_clust_instances=None, min_clust_instances_pct=0.85,\n",
    "               max_clust_instances=np.inf):\n",
    "    # Condition precalculation\n",
    "    if min_clust_instances_pct: # If % was defined\n",
    "        min_clust_instances = round(data.shape[0] * min_clust_instances_pct)\n",
    "    elif not min_clust_instances: # Else, if nominal amount was not specified\n",
    "        min_clust_instances = 100\n",
    "    # Code\n",
    "    scores, clusters, instances = [], [], []\n",
    "    for m in min_samples:\n",
    "        row_scores, row_clusters, row_instances = [], [], []\n",
    "        for e in eps_values:\n",
    "            db = DBSCAN(min_samples=m, eps=e, metric='precomputed').fit(data)\n",
    "            # Get only non anomalous instances and indices\n",
    "            non_a = db.labels_ != -1 # [False, ..., False] if all are outliers\n",
    "            non_a_idxs = np.argwhere(non_a==True)\n",
    "            non_a_idxs = non_a_idxs.reshape(non_a_idxs.shape[0])\n",
    "            # Calculate conditions\n",
    "            n_clusters = len(np.unique(db.labels_[non_a])) # 0 if all are outliers\n",
    "            n_instances = len(db.labels_[non_a]) # 0 if all are outliers\n",
    "            # Apply conditions (why does it output NaN and not None?)\n",
    "            valid_n_clusters = n_clusters >= min_no_clusters and n_clusters <= max_no_clusters\n",
    "            valid_n_cl_instances = n_instances >= min_clust_instances and n_instances <= max_clust_instances\n",
    "            if (valid_n_clusters and valid_n_cl_instances):\n",
    "                non_a_data = get_sim_mx_subset(data, non_a_idxs)\n",
    "                score = silhouette_score(non_a_data, db.labels_[non_a], metric='precomputed')\n",
    "            else:\n",
    "                score = None\n",
    "            # Store results\n",
    "            row_scores.append(score)\n",
    "            row_clusters.append(n_clusters)\n",
    "            row_instances.append(n_instances)\n",
    "        # Store row results\n",
    "        scores.append(row_scores)\n",
    "        clusters.append(row_clusters)\n",
    "        instances.append(row_instances)\n",
    "    # Prepare and return values\n",
    "    ms_axis = pd.Index(min_samples, name='Min_samples')\n",
    "    eps_axis = pd.Index(eps_values, name='Epsilon')\n",
    "    df_scores = pd.DataFrame(scores, index=ms_axis, columns=eps_axis)\n",
    "    df_clusters = pd.DataFrame(clusters, index=ms_axis, columns=eps_axis)\n",
    "    df_instances = pd.DataFrame(instances, index=ms_axis, columns=eps_axis)\n",
    "    return df_scores, df_clusters, df_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(m, eps, scores_df, instances_df, clusters_df):\n",
    "    score = round(scores_df.loc[m][eps], 4)\n",
    "    instances = instances_df.loc[m][eps]\n",
    "    clusters = clusters_df.loc[m][eps]\n",
    "    print(f'DBSCAN using parameters m={m} and eps={eps} yields the next clustering results:')\n",
    "    print()\n",
    "    print(f'- Sil. score: {score}')\n",
    "    print(f'- {instances} clustered instances into {clusters} clusters')\n",
    "    print(f'- Avg. of {round(instances/clusters, 2)} instances per cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[splits[0][0]].shape[0] * 0.85 # about 135 clustered instances are needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split #0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_split_0 = get_sim_mx_subset(X, splits[0][0])\n",
    "X_split_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs, dfc, dfi = fit_dbscan_sim_mx(X_split_0, range(2, 8), range(10, 18))\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(2, 11, dfs, dfi, dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterable_params.append([2, 11, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_split_1 = get_sim_mx_subset(X, splits[1][0])\n",
    "X_split_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs, dfc, dfi = fit_dbscan_sim_mx(X_split_1, range(2, 8), range(10, 18))\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(2, 11, dfs, dfi, dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterable_params.append([2, 11, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_split_2 = get_sim_mx_subset(X, splits[2][0])\n",
    "X_split_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs, dfc, dfi = fit_dbscan_sim_mx(X_split_2, range(2, 8), range(10, 18))\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(2, 11, dfs, dfi, dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterable_params.append([2, 11, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_split_3 = get_sim_mx_subset(X, splits[3][0])\n",
    "X_split_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs, dfc, dfi = fit_dbscan_sim_mx(X_split_3, range(2, 8), range(10, 18))\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(2, 11, dfs, dfi, dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterable_params.append([2, 11, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_sim_mx_subset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c63fb635497c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_split_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sim_mx_subset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_split_4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_sim_mx_subset' is not defined"
     ]
    }
   ],
   "source": [
    "X_split_4 = get_sim_mx_subset(X, splits[4][0])\n",
    "X_split_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs, dfc, dfi = fit_dbscan_sim_mx(X_split_4, range(2, 8), range(10, 18))\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(2, 11, dfs, dfi, dfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterable_params.append([2, 11, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clusterable parameters for each split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterable_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indiv_clustering_results(params):\n",
    "    '''Returns a dictionary mapping the name of an image\n",
    "    with the cluster it belongs to'''\n",
    "    # Preconditions\n",
    "    split_idx = params[2]\n",
    "    train_idxs = splits[split_idx][0]\n",
    "    # Prepare data (always X, not feats_df)\n",
    "    sim_mx_subset = get_sim_mx_subset(X, train_idxs)\n",
    "    img_names = X_names[train_idxs]\n",
    "    # Perform clustering\n",
    "    dbscan = DBSCAN(min_samples=params[0], eps=params[1], metric='precomputed')\n",
    "    dbscan = dbscan.fit(sim_mx_subset)\n",
    "    # Generate {img_name : label} mapping\n",
    "    name_label_map = {name: label for name, label in zip(img_names, dbscan.labels_)}\n",
    "    return name_label_map\n",
    "\n",
    "def get_global_clustering_results(params_set):\n",
    "    '''Returns a dictionary mapping the index of every param set\n",
    "    in 'params' arg. with the clustering results generated with that param. set'''\n",
    "    results = {}\n",
    "    for params in params_set:\n",
    "        # Create { split_idx: cluster_labels} pair\n",
    "        results[params[2]] = get_indiv_clustering_results(params)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_results = get_global_clustering_results(clusterable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: Number of elements should be the same as clusters detected in clustering phase\n",
    "for split_idx in cl_results.keys(): print(len(np.unique(list(cl_results[split_idx].values())))-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Prototypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our experiment, we want to predict the vote count for a new image, based on the proximity it has to the avaliable clusters. These clusters are composed of many data points, so the proximity of a new data point to a cluster can be measured in different ways, like taking the distance between the new point and the nearest clustered point in the dataset.   \n",
    "However, this approach can be biased when new poins get associated to the cluster taking in account the nearest point of a cluster instead of the overall position of a cluster. To avoid this, for each cluster we calculate a \"prototype\", a data point which is the centroid of all the data points in a cluster. This way, we can measure the distance to the general position of a cluster in a more confident way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vote prototypes (Solution of cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_indiv_vote_prototypes(cl_result, ignore_noise=True):\n",
    "    # Separate image votes according to the clusters they belong to\n",
    "    votes_by_cluster = {}\n",
    "    for img_name, cl_idx in cl_result.items():\n",
    "        if ignore_noise and cl_idx == -1: continue # ignore noise cluster\n",
    "        img_votes = votes_df.loc[img_name].values[:-1]\n",
    "        if cl_idx not in votes_by_cluster.keys(): votes_by_cluster[cl_idx] = [img_votes]\n",
    "        else: votes_by_cluster[cl_idx].append(img_votes)\n",
    "    # For each cluster, calculate their vote prototype\n",
    "    vote_prts_by_cluster = {}\n",
    "    for cl_idx, cl_votes in votes_by_cluster.items():\n",
    "        unrounded_prt = np.average(np.array(cl_votes,'uint8'), axis=0)\n",
    "        vote_prts_by_cluster[cl_idx] = np.array(np.round(unrounded_prt), 'int')\n",
    "    return vote_prts_by_cluster\n",
    "    \n",
    "def get_global_vote_prototypes(cl_results, ignore_noise=True):\n",
    "    global_vote_prototypes = {}\n",
    "    for i, cl_result in cl_results.items():\n",
    "        global_vote_prototypes[i] = gen_indiv_vote_prototypes(cl_result, ignore_noise=ignore_noise)\n",
    "    return global_vote_prototypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Prototypes (Description of cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_indiv_feat_prototypes(cl_result, ignore_noise=True):\n",
    "    # Separate image votes according to the clusters they belong to\n",
    "    feats_by_cluster = {}\n",
    "    for img_name, cl_idx in cl_result.items():\n",
    "        if ignore_noise and cl_idx == -1: continue # ignore noise cluster\n",
    "        img_feats = votes_df.loc[img_name].values[:-1] # PENDING\n",
    "        if cl_idx not in feats_by_cluster.keys(): feats_by_cluster[cl_idx] = [img_feats]\n",
    "        else: feats_by_cluster[cl_idx].append(img_feats)\n",
    "    # For each cluster, calculate their feature prototype\n",
    "    feat_prts_by_cluster = {}\n",
    "    for cl_idx, cl_feats in feats_by_cluster.items():\n",
    "        unrounded_prt = np.average(np.array(cl_feats,'uint8'), axis=0)\n",
    "        feat_prts_by_cluster[cl_idx] = np.array(np.round(unrounded_prt), 'int')\n",
    "    return feat_prts_by_cluster\n",
    "    \n",
    "def get_global_feat_prototypes(cl_results, ignore_noise=True):\n",
    "    global_feat_prototypes = {}\n",
    "    for i, cl_result in cl_results.items():\n",
    "        global__feat_prototypes[i] = gen_indiv_feat_prototypes(cl_result, ignore_noise=ignore_noise)\n",
    "    return global_feat_prototypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate both prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_vote_prototypes = get_global_vote_prototypes(cl_results)\n",
    "global_feats_prototypes = get_global_feats_prototypes(cl_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array([5, 4, 4, 0]),\n",
       " 1: array([7, 2, 5, 1]),\n",
       " 2: array([8, 2, 3, 2]),\n",
       " 3: array([ 8, 10,  2,  0]),\n",
       " 4: array([7, 2, 6, 0]),\n",
       " 5: array([8, 2, 2, 1]),\n",
       " 6: array([7, 4, 2, 0]),\n",
       " 7: array([9, 2, 1, 2]),\n",
       " 8: array([6, 5, 3, 0]),\n",
       " 9: array([6, 3, 4, 0]),\n",
       " 10: array([6, 5, 2, 1]),\n",
       " 11: array([11,  2,  6,  0]),\n",
       " 12: array([8, 0, 4, 0]),\n",
       " 13: array([5, 2, 5, 0]),\n",
       " 14: array([8, 2, 2, 0])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check: No. of elements should be the same as no. of clusters detected in clustering phase\n",
    "global_vote_prototypes[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: No. of elements should be the same as no. of clusters detected in clustering phase\n",
    "global_feats_prototypes[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vote Count Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_idxs_per_cluster(cl_results, ignore_noise=True):\n",
    "    img_idxs_per_cluster = {}\n",
    "    for img_name, cl_idx in cl_results.items():\n",
    "        if cl_idx==-1 and ignore_noise: continue # ignore noise cluster\n",
    "        img_idx = np.argwhere(X_names == img_name)[0][0]\n",
    "        if cl_idx not in img_idxs_per_cluster.keys():\n",
    "            img_idxs_per_cluster[cl_idx] = [img_idx]\n",
    "        else:\n",
    "            img_idxs_per_cluster[cl_idx].append(img_idx)\n",
    "    return img_idxs_per_cluster\n",
    "\n",
    "def get_dist_to_clusters(img_idx, img_idxs_per_cluster):\n",
    "    dist_to_clusters = {}\n",
    "    for cl_idx, img_idxs in img_idxs_per_cluster.items():\n",
    "        distances = X[img_idx, img_idxs]\n",
    "        dist_to_clusters[cl_idx] = np.average(distances)\n",
    "    return dist_to_clusters\n",
    "\n",
    "def get_nearest_clusters_indices(dist_to_clusters, k):\n",
    "    if k >= len(dist_to_clusters): nearest_cls_idxs = list(dist_to_clusters.keys())\n",
    "    else:\n",
    "        nearest_cls_idxs = []\n",
    "        for i in range(k): # K times...\n",
    "            nearest_cl_idx, min_dist = None, np.inf\n",
    "            # ...iterate searching the nearest cluster\n",
    "            for cl_idx, dist in dist_to_clusters.items():\n",
    "                if cl_idx in nearest_cls_idxs: continue # ignore prev. found nearest clusters\n",
    "                if dist < min_dist: nearest_cl_idx, min_dist = cl_idx, dist\n",
    "            nearest_cls_idxs.append(nearest_cl_idx)\n",
    "    return nearest_cls_idxs\n",
    "\n",
    "def get_indiv_vote_predictions(prototypes, cl_results, split_idx, k):\n",
    "    vote_predictions = {}\n",
    "    # Prepare data\n",
    "    test_idxs = splits[split_idx][1]\n",
    "    img_idxs_per_cluster = get_img_idxs_per_cluster(cl_results)\n",
    "    # For each test image...\n",
    "    for test_img_idx in test_idxs:\n",
    "        # Measure average distances to each cluster\n",
    "        dist_to_clusters = get_dist_to_clusters(test_img_idx, img_idxs_per_cluster)\n",
    "        # Using those distances, find the nearest k clusters\n",
    "        kn_clusters_idxs =  get_nearest_clusters_indices(dist_to_clusters, k=k)\n",
    "        # Aggregate the vote prototypes of the clusters associated with those distances\n",
    "        nearest_prototypes = [prototypes[kn_cl_idx] for kn_cl_idx in kn_clusters_idxs]\n",
    "        unrounded_vcp = np.average(np.array(nearest_prototypes), axis=0)\n",
    "        vote_count_prediction = np.round(unrounded_vcp)\n",
    "        # Assoaciate name of imge with its vote prediction\n",
    "        test_img_name = X_names[test_img_idx]\n",
    "        vote_predictions[test_img_name] = vote_count_prediction\n",
    "    return vote_predictions\n",
    "\n",
    "def get_global_vote_predictions(global_prototypes, global_cl_results, k):\n",
    "    global_vote_predictions = {}\n",
    "    for split_idx in global_cl_results.keys():\n",
    "        # Create { split_idx: vote_predictions } pairs\n",
    "        global_vote_predictions[split_idx] = get_indiv_vote_predictions(global_prototypes[split_idx], global_cl_results[split_idx], split_idx, k=k)\n",
    "    return global_vote_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_vote_predictions_k1 = get_global_vote_predictions(global_prototypes, cl_results, k=1)\n",
    "global_vote_predictions_k3 = get_global_vote_predictions(global_prototypes, cl_results, k=3)\n",
    "global_vote_predictions_k5 = get_global_vote_predictions(global_prototypes, cl_results, k=5)\n",
    "global_vote_predictions_k7 = get_global_vote_predictions(global_prototypes, cl_results, k=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'2388889__hotdog__0.99999714.jpg': array([8., 3., 3., 1.]),\n",
       "  '2417881__zebra__0.9999945.jpg': array([8., 3., 3., 1.]),\n",
       "  '2403403__banana__0.9999926.jpg': array([7., 4., 2., 1.]),\n",
       "  '2381941__zebra__0.9999914.jpg': array([8., 3., 3., 1.]),\n",
       "  '2403741__zebra__0.99999523.jpg': array([7., 3., 4., 1.]),\n",
       "  '2404281__zebra__0.999998.jpg': array([8., 3., 3., 1.]),\n",
       "  '2416627__zebra__0.9999987.jpg': array([8., 3., 3., 1.]),\n",
       "  '2391964__flamingo__1.0.jpg': array([8., 3., 3., 1.]),\n",
       "  '2404583__umbrella__0.99999297.jpg': array([7., 3., 3., 1.]),\n",
       "  '2409637__four-poster__0.99999464.jpg': array([7., 3., 4., 0.]),\n",
       "  '2380669__parking_meter__0.9999993.jpg': array([7., 3., 4., 0.]),\n",
       "  '2411196__crane__0.9999995.jpg': array([8., 3., 3., 1.]),\n",
       "  '134__zebra__0.9999949.jpg': array([8., 3., 3., 1.]),\n",
       "  '2405905__traffic_light__0.99999535.jpg': array([7., 3., 3., 1.]),\n",
       "  '2404127__zebra__0.9999933.jpg': array([8., 3., 3., 1.]),\n",
       "  '2406857__zebra__0.9999894.jpg': array([8., 3., 3., 1.]),\n",
       "  '2414277__zebra__0.9999908.jpg': array([8., 3., 3., 1.]),\n",
       "  '2385298__parking_meter__0.9999865.jpg': array([8., 3., 3., 1.]),\n",
       "  '2406887__ski__0.99999785.jpg': array([8., 3., 3., 1.]),\n",
       "  '2416228__parking_meter__0.9999914.jpg': array([7., 3., 4., 0.]),\n",
       "  '2415402__zebra__0.99998903.jpg': array([8., 3., 3., 1.]),\n",
       "  '2408701__zebra__0.9999981.jpg': array([7., 3., 4., 1.]),\n",
       "  '2389484__street_sign__0.99998474.jpg': array([7., 3., 3., 1.]),\n",
       "  '2417395__zebra__0.9999993.jpg': array([8., 3., 3., 1.]),\n",
       "  '2384512__zebra__0.99999726.jpg': array([7., 3., 4., 1.]),\n",
       "  '2391918__steam_locomotive__0.99999845.jpg': array([8., 3., 3., 1.]),\n",
       "  '2404229__zebra__0.99998367.jpg': array([8., 3., 3., 1.]),\n",
       "  '2381968__ski__0.999984.jpg': array([8., 3., 3., 1.]),\n",
       "  '2413495__traffic_light__0.9999925.jpg': array([7., 3., 3., 1.]),\n",
       "  '2398585__bow_tie__0.9999838.jpg': array([8., 3., 3., 1.]),\n",
       "  '2398771__traffic_light__0.99999.jpg': array([7., 4., 3., 0.]),\n",
       "  '2400121__pizza__0.9999962.jpg': array([8., 3., 3., 1.]),\n",
       "  '2407951__zebra__0.9999975.jpg': array([8., 3., 3., 1.]),\n",
       "  '2386193__broccoli__0.9999924.jpg': array([8., 3., 2., 1.]),\n",
       "  '2410903__steam_locomotive__0.9999876.jpg': array([8., 3., 3., 1.]),\n",
       "  '2399675__zebra__0.9999883.jpg': array([8., 3., 3., 1.]),\n",
       "  '2381932__traffic_light__0.99999964.jpg': array([7., 3., 3., 1.]),\n",
       "  '691__cheetah__0.99999213.jpg': array([8., 3., 3., 1.]),\n",
       "  '2392405__parking_meter__0.9999993.jpg': array([7., 3., 4., 0.]),\n",
       "  '2412908__zebra__0.99998975.jpg': array([8., 3., 3., 1.])},\n",
       " 1: {'2390296__umbrella__0.99999106.jpg': array([8., 3., 3., 1.]),\n",
       "  '2405042__parking_meter__0.99999094.jpg': array([8., 2., 4., 1.]),\n",
       "  '2415402__zebra__0.99998903.jpg': array([8., 2., 4., 1.]),\n",
       "  '2406209__brown_bear__0.999985.jpg': array([8., 2., 4., 1.]),\n",
       "  '2403199__zebra__0.9999869.jpg': array([8., 2., 4., 1.]),\n",
       "  '2408719__ski__0.99999297.jpg': array([8., 2., 4., 1.]),\n",
       "  '2414277__zebra__0.9999908.jpg': array([8., 2., 4., 1.]),\n",
       "  '2405479__traffic_light__0.9999939.jpg': array([7., 3., 3., 1.]),\n",
       "  '2415737__parking_meter__0.99999785.jpg': array([8., 2., 4., 1.]),\n",
       "  '2388889__hotdog__0.99999714.jpg': array([8., 2., 3., 1.]),\n",
       "  '2411390__parking_meter__0.9999988.jpg': array([8., 2., 4., 1.]),\n",
       "  '2416228__parking_meter__0.9999914.jpg': array([7., 3., 4., 0.]),\n",
       "  '691__cheetah__0.99999213.jpg': array([8., 2., 4., 1.]),\n",
       "  '2389163__zebra__0.9999957.jpg': array([8., 2., 4., 1.]),\n",
       "  '2408701__zebra__0.9999981.jpg': array([7., 2., 4., 1.]),\n",
       "  '2392579__zebra__0.9999969.jpg': array([8., 2., 4., 1.]),\n",
       "  '2389484__street_sign__0.99998474.jpg': array([7., 3., 4., 1.]),\n",
       "  '2391408__traffic_light__0.99999654.jpg': array([7., 3., 3., 1.]),\n",
       "  '2412939__forklift__0.9999883.jpg': array([8., 2., 3., 1.]),\n",
       "  '2382792__umbrella__0.9999838.jpg': array([7., 3., 3., 1.]),\n",
       "  '2378170__zebra__0.9999902.jpg': array([8., 2., 4., 1.]),\n",
       "  '2379086__zebra__0.9999975.jpg': array([8., 2., 4., 1.]),\n",
       "  '2389324__zebra__0.9999993.jpg': array([8., 2., 4., 1.]),\n",
       "  '2417938__banana__0.9999944.jpg': array([7., 3., 3., 1.]),\n",
       "  '2396153__brown_bear__0.9999938.jpg': array([8., 2., 4., 1.]),\n",
       "  '2414384__ski__0.9999949.jpg': array([8., 2., 3., 1.]),\n",
       "  '2393774__zebra__0.9999995.jpg': array([7., 2., 4., 1.]),\n",
       "  '2391918__steam_locomotive__0.99999845.jpg': array([8., 2., 4., 1.]),\n",
       "  '2387437__parking_meter__0.9999839.jpg': array([8., 2., 4., 1.]),\n",
       "  '2404955__banana__0.9999995.jpg': array([7., 3., 2., 1.]),\n",
       "  '2392818__park_bench__0.99999.jpg': array([8., 2., 4., 1.]),\n",
       "  '2380865__traffic_light__0.99999714.jpg': array([7., 3., 3., 1.]),\n",
       "  '2392349__umbrella__0.9999994.jpg': array([8., 3., 3., 1.]),\n",
       "  '2411784__traffic_light__0.9999945.jpg': array([7., 3., 3., 1.]),\n",
       "  '2386049__king_penguin__0.99999917.jpg': array([8., 2., 4., 1.]),\n",
       "  '2406857__zebra__0.9999894.jpg': array([8., 2., 4., 1.]),\n",
       "  '2380319__broccoli__0.9999957.jpg': array([8., 2., 3., 1.]),\n",
       "  '2409589__zebra__0.99999976.jpg': array([8., 2., 4., 1.]),\n",
       "  '2377698__zebra__0.9999999.jpg': array([7., 2., 4., 1.]),\n",
       "  '2380669__parking_meter__0.9999993.jpg': array([8., 2., 4., 1.])},\n",
       " 2: {'2392349__umbrella__0.9999994.jpg': array([8., 2., 2., 1.]),\n",
       "  '2408970__zebra__0.9999865.jpg': array([7., 2., 4., 1.]),\n",
       "  '2414335__refrigerator__0.9999889.jpg': array([7., 2., 3., 1.]),\n",
       "  '2401691__pineapple__0.999998.jpg': array([7., 2., 3., 1.]),\n",
       "  '2391964__flamingo__1.0.jpg': array([7., 2., 3., 1.]),\n",
       "  '2389484__street_sign__0.99998474.jpg': array([7., 2., 3., 1.]),\n",
       "  '2409550__street_sign__0.99999905.jpg': array([7., 2., 4., 1.]),\n",
       "  '2391408__traffic_light__0.99999654.jpg': array([7., 3., 3., 0.]),\n",
       "  '2411407__zebra__0.9999969.jpg': array([7., 2., 3., 1.]),\n",
       "  '2407788__pizza__0.99999785.jpg': array([8., 2., 2., 1.]),\n",
       "  '2395787__pizza__0.99999535.jpg': array([8., 2., 3., 1.]),\n",
       "  '2380905__gondola__0.9999888.jpg': array([7., 2., 4., 1.]),\n",
       "  '2389163__zebra__0.9999957.jpg': array([7., 2., 3., 1.]),\n",
       "  '2386456__zebra__0.9999989.jpg': array([7., 2., 3., 1.]),\n",
       "  '2402745__bullet_train__0.99999857.jpg': array([7., 2., 3., 1.]),\n",
       "  '2417395__zebra__0.9999993.jpg': array([7., 2., 3., 1.]),\n",
       "  '2401383__slug__0.9999933.jpg': array([8., 2., 2., 1.]),\n",
       "  '691__cheetah__0.99999213.jpg': array([7., 2., 3., 1.]),\n",
       "  '2384755__street_sign__0.9999924.jpg': array([7., 2., 3., 1.]),\n",
       "  '2414760__zebra__0.9999895.jpg': array([7., 2., 3., 1.]),\n",
       "  '2399217__umbrella__0.9999863.jpg': array([8., 2., 2., 1.]),\n",
       "  '2401224__zebra__0.9999882.jpg': array([7., 2., 3., 1.]),\n",
       "  '4099__pool_table__0.9999945.jpg': array([7., 2., 3., 1.]),\n",
       "  '2382183__pizza__0.99998593.jpg': array([8., 2., 2., 1.]),\n",
       "  '2412402__zebra__0.9999877.jpg': array([7., 2., 3., 1.]),\n",
       "  '2383569__parking_meter__0.9999988.jpg': array([7., 2., 4., 1.]),\n",
       "  '2383286__zebra__0.99999857.jpg': array([7., 2., 4., 1.]),\n",
       "  '2410336__zebra__0.99999547.jpg': array([7., 2., 4., 1.]),\n",
       "  '2392324__traffic_light__0.9999964.jpg': array([7., 3., 3., 0.]),\n",
       "  '2405041__broccoli__0.99999845.jpg': array([8., 2., 3., 1.]),\n",
       "  '2401906__parking_meter__1.0.jpg': array([7., 2., 4., 0.]),\n",
       "  '2407951__zebra__0.9999975.jpg': array([7., 2., 3., 1.]),\n",
       "  '2414513__bagel__0.9999893.jpg': array([8., 2., 2., 1.]),\n",
       "  '2378170__zebra__0.9999902.jpg': array([7., 2., 3., 1.]),\n",
       "  '2404127__zebra__0.9999933.jpg': array([7., 2., 3., 1.]),\n",
       "  '2409063__zebra__0.999997.jpg': array([7., 2., 3., 1.]),\n",
       "  '2382792__umbrella__0.9999838.jpg': array([7., 2., 3., 1.]),\n",
       "  '2389324__zebra__0.9999993.jpg': array([7., 2., 3., 1.]),\n",
       "  '2399675__zebra__0.9999883.jpg': array([7., 2., 3., 1.]),\n",
       "  '2411097__zebra__0.9999974.jpg': array([7., 2., 4., 1.])},\n",
       " 3: {'2401906__parking_meter__1.0.jpg': array([7., 2., 4., 0.]),\n",
       "  '2416228__parking_meter__0.9999914.jpg': array([8., 2., 3., 1.]),\n",
       "  '2403403__banana__0.9999926.jpg': array([7., 3., 3., 1.]),\n",
       "  '2409765__zebra__0.99999833.jpg': array([8., 2., 4., 0.]),\n",
       "  '2392818__park_bench__0.99999.jpg': array([8., 2., 4., 0.]),\n",
       "  '2416627__zebra__0.9999987.jpg': array([8., 2., 4., 0.]),\n",
       "  '2406887__ski__0.99999785.jpg': array([8., 2., 4., 0.]),\n",
       "  '2402132__traffic_light__0.9999951.jpg': array([7., 3., 3., 0.]),\n",
       "  '2380905__gondola__0.9999888.jpg': array([7., 2., 4., 0.]),\n",
       "  '2416408__zebra__0.9999962.jpg': array([8., 2., 4., 0.]),\n",
       "  '2388889__hotdog__0.99999714.jpg': array([7., 2., 3., 1.]),\n",
       "  '2391964__flamingo__1.0.jpg': array([8., 2., 4., 0.]),\n",
       "  '2392730__pizza__0.9999974.jpg': array([7., 2., 3., 1.]),\n",
       "  '2403199__zebra__0.9999869.jpg': array([8., 2., 4., 0.]),\n",
       "  '2407130__umbrella__0.9999888.jpg': array([7., 2., 3., 1.]),\n",
       "  '2402264__zebra__0.9999931.jpg': array([8., 2., 4., 0.]),\n",
       "  '2411645__parking_meter__0.999985.jpg': array([7., 2., 3., 1.]),\n",
       "  '2382792__umbrella__0.9999838.jpg': array([7., 2., 3., 0.]),\n",
       "  '2404127__zebra__0.9999933.jpg': array([8., 2., 4., 0.]),\n",
       "  '2411784__traffic_light__0.9999945.jpg': array([7., 2., 3., 1.]),\n",
       "  '2392324__traffic_light__0.9999964.jpg': array([7., 3., 3., 0.]),\n",
       "  '2378523__banana__0.99999785.jpg': array([7., 3., 3., 1.]),\n",
       "  '2409822__steam_locomotive__0.9999906.jpg': array([8., 2., 3., 1.]),\n",
       "  '2383286__zebra__0.99999857.jpg': array([7., 2., 4., 0.]),\n",
       "  '2413227__park_bench__0.99998546.jpg': array([8., 2., 4., 0.]),\n",
       "  '2403338__seat_belt__0.99999917.jpg': array([8., 2., 3., 1.]),\n",
       "  '2404955__banana__0.9999995.jpg': array([7., 3., 3., 1.]),\n",
       "  '2382474__bow_tie__0.9999982.jpg': array([8., 2., 4., 0.]),\n",
       "  '2391701__zebra__0.9999912.jpg': array([7., 2., 4., 0.]),\n",
       "  '2396034__remote_control__0.9999856.jpg': array([7., 2., 3., 1.]),\n",
       "  '2402745__bullet_train__0.99999857.jpg': array([8., 2., 4., 0.]),\n",
       "  '1328__coil__0.99999607.jpg': array([7., 2., 3., 1.]),\n",
       "  '2411841__zebra__0.99999833.jpg': array([8., 2., 4., 0.]),\n",
       "  '2397486__zebra__0.9999875.jpg': array([8., 2., 4., 0.]),\n",
       "  '2415102__zebra__0.9999876.jpg': array([8., 2., 4., 0.]),\n",
       "  '2409472__umbrella__0.9999845.jpg': array([7., 2., 3., 1.]),\n",
       "  '2405042__parking_meter__0.99999094.jpg': array([7., 2., 3., 1.]),\n",
       "  '2389163__zebra__0.9999957.jpg': array([8., 2., 4., 0.]),\n",
       "  '2380319__broccoli__0.9999957.jpg': array([8., 2., 3., 1.]),\n",
       "  '2408701__zebra__0.9999981.jpg': array([7., 2., 4., 0.])},\n",
       " 4: {'2381932__traffic_light__0.99999964.jpg': array([7., 3., 3., 1.]),\n",
       "  '2379489__parking_meter__0.9999989.jpg': array([8., 2., 4., 0.]),\n",
       "  '2382474__bow_tie__0.9999982.jpg': array([8., 2., 4., 1.]),\n",
       "  '2398585__bow_tie__0.9999838.jpg': array([8., 2., 4., 1.]),\n",
       "  '2392730__pizza__0.9999974.jpg': array([8., 2., 3., 1.]),\n",
       "  '2377698__zebra__0.9999999.jpg': array([7., 2., 4., 1.]),\n",
       "  '2411646__banana__0.99999595.jpg': array([7., 3., 3., 1.]),\n",
       "  '2416516__zebra__0.99999714.jpg': array([8., 2., 4., 1.]),\n",
       "  '2404583__umbrella__0.99999297.jpg': array([7., 3., 3., 1.]),\n",
       "  '2385298__parking_meter__0.9999865.jpg': array([8., 2., 4., 0.]),\n",
       "  '2412402__zebra__0.9999877.jpg': array([8., 2., 4., 1.]),\n",
       "  '2417395__zebra__0.9999993.jpg': array([8., 2., 4., 1.]),\n",
       "  '2395787__pizza__0.99999535.jpg': array([8., 2., 3., 1.]),\n",
       "  '2391918__steam_locomotive__0.99999845.jpg': array([8., 3., 3., 1.]),\n",
       "  '2391964__flamingo__1.0.jpg': array([8., 2., 4., 1.]),\n",
       "  '2415910__zebra__0.9999962.jpg': array([8., 2., 4., 1.]),\n",
       "  '2395510__traffic_light__0.9999993.jpg': array([7., 3., 3., 1.]),\n",
       "  '2416627__zebra__0.9999987.jpg': array([8., 2., 4., 1.]),\n",
       "  '2407130__umbrella__0.9999888.jpg': array([8., 3., 3., 1.]),\n",
       "  '2402132__traffic_light__0.9999951.jpg': array([7., 3., 3., 1.]),\n",
       "  '2401906__parking_meter__1.0.jpg': array([8., 2., 4., 0.]),\n",
       "  '2392579__zebra__0.9999969.jpg': array([8., 2., 4., 1.]),\n",
       "  '2387034__zebra__0.9999896.jpg': array([8., 2., 4., 1.]),\n",
       "  '2383286__zebra__0.99999857.jpg': array([7., 2., 4., 1.]),\n",
       "  '2405042__parking_meter__0.99999094.jpg': array([8., 2., 4., 0.]),\n",
       "  '2414384__ski__0.9999949.jpg': array([8., 2., 3., 1.]),\n",
       "  '2409550__street_sign__0.99999905.jpg': array([7., 3., 4., 1.]),\n",
       "  '2380019__zebra__0.9999926.jpg': array([8., 2., 4., 1.]),\n",
       "  '2385187__street_sign__0.99999595.jpg': array([7., 3., 3., 1.]),\n",
       "  '2382913__zebra__0.9999883.jpg': array([8., 2., 4., 1.]),\n",
       "  '2400622__zebra__0.9999901.jpg': array([8., 2., 4., 1.]),\n",
       "  '2400121__pizza__0.9999962.jpg': array([8., 2., 3., 1.]),\n",
       "  '2405280__zebra__0.9999938.jpg': array([7., 2., 4., 1.]),\n",
       "  '2409472__umbrella__0.9999845.jpg': array([8., 3., 3., 1.]),\n",
       "  '2410974__toilet_seat__0.9999939.jpg': array([8., 2., 3., 1.]),\n",
       "  '2392124__zebra__0.99999523.jpg': array([8., 2., 4., 1.]),\n",
       "  '2408592__goose__0.999998.jpg': array([8., 2., 4., 1.]),\n",
       "  '2404051__street_sign__0.9999999.jpg': array([7., 3., 3., 1.]),\n",
       "  '2386049__king_penguin__0.99999917.jpg': array([8., 2., 4., 1.]),\n",
       "  '2411372__parking_meter__0.999995.jpg': array([7., 2., 4., 1.])}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_vote_predictions_k5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(p1, p2, metric):\n",
    "    if metric == 'rmse': return np.sum(np.square(p1 - p2))\n",
    "    elif metric == 'manhattan': return np.sum(np.abs(p1 - p2))\n",
    "    else: print('Unknown metric type')\n",
    "\n",
    "def eval_indiv_vote_preds(vote_predictions, metric):\n",
    "    vote_distances = []\n",
    "    for img_name, vote_pred in vote_predictions.items():\n",
    "        # Fetch real votes and compare with vote predictions\n",
    "        real_votes = votes_df.loc[img_name].values[:4]\n",
    "        distance = calc_distance(real_votes, vote_pred, metric)\n",
    "        vote_distances.append(distance)\n",
    "    vote_distances = np.array(vote_distances)\n",
    "    if metric=='rmse': metrics = {'rmse': round(np.sqrt(np.average(vote_distances)), 2)}\n",
    "    elif metric=='manhattan': metrics = {'manhattan': (np.average(vote_distances), 2)}\n",
    "    else:\n",
    "        metrics = {\n",
    "            'average': round(np.average(vote_distances), 2),\n",
    "            'std. dev.': round(np.std(vote_distances), 2),\n",
    "            'range': [round(np.min(vote_distances), 2), round(np.max(vote_distances), 2)],\n",
    "        }\n",
    "    return metrics\n",
    "\n",
    "def eval_global_vote_preds(global_vote_predictions, metric):\n",
    "    global_metrics = {}\n",
    "    # Calculate metrics for each split\n",
    "    for split_idx, vote_predictions in global_vote_predictions.items():\n",
    "        global_metrics[split_idx] = eval_indiv_vote_preds(vote_predictions, metric)\n",
    "    # Aggregate metrics for all splits\n",
    "    global_metrics['global'] = {}\n",
    "    for metric_type in global_metrics[0].keys():\n",
    "        metrics_per_type = [metrics[metric_type] for split_key, metrics in global_metrics.items() if split_key != 'global']\n",
    "        avgd_metrics_per_type = np.round(np.average(np.array(metrics_per_type), axis=0), 2)\n",
    "        if metric_type == 'range': avgd_metrics_per_type = list(avgd_metrics_per_type)\n",
    "        global_metrics['global'][metric_type] = avgd_metrics_per_type\n",
    "    return global_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC = 'rmse'\n",
    "global_vote_metrics_k1 = eval_global_vote_preds(global_vote_predictions_k1, metric=METRIC)\n",
    "global_vote_metrics_k3 = eval_global_vote_preds(global_vote_predictions_k3, metric=METRIC)\n",
    "global_vote_metrics_k5 = eval_global_vote_preds(global_vote_predictions_k5, metric=METRIC)\n",
    "global_vote_metrics_k7 = eval_global_vote_preds(global_vote_predictions_k7, metric=METRIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 4.08}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_vote_metrics_k1['global']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 4.24}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_vote_metrics_k3['global']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 4.34}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_vote_metrics_k5['global']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 4.44}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_vote_metrics_k7['global']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous results shine a light about the viability to predict the vote count for a new image given the vote prototypes of previously generated image clusters.   \n",
    "\n",
    "In average, the predicted vote count for a new image differs by 6 votes compared to the real vote count. The difference between vote count shows a ascending tendence proportional to the number of nearest clusters used in the vote count prediction, although the growing rate is very small. In the end, this means that when predicting the vote count for a new image, it is recommended to use the vote prototype of only the nearest cluster.   \n",
    "\n",
    "Additional metrics also show that the distribution of vote count differences shows a gaussian shape with a slight skeweness to the right, i.e. towards higher vote differences). The standard deviation shows that the majority of vote differences are between +-3 to the average vote difference. Given that the average vote difference is 6, this means that the majority of vote differences will be inside the 3-9 range.\n",
    "\n",
    "Taking in account that for every image around 30 votes were casted, the difference in vote count prediction is pretty large. A difference of 6 votes when predicting votes can be really important. However, we need to calculate vote count proportion differences, beacuase, at the end of the day, proportions are also a important factor in deciding which techniques are better for new images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
